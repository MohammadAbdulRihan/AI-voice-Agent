"""
AI Voice Agent - Refactored FastAPI Application

Day 14: Code refactoring, clean architecture, and production readiness
- Separated services into dedicated modules
- Added comprehensive logging
- Created Pydantic schemas for all requests/responses  
- Improved error handling and code maintainability
- Organized code structure for scalability

Author: Mohammad Abdul Rihan
Repository: https://github.com/MohammadAbdulRihan/AI-voice-Agent
"""

import os
import logging
import shutil
from pathlib import Path
from datetime import datetime
from typing import Optional

from fastapi import FastAPI, Request, HTTPException, UploadFile, File, WebSocket, WebSocketDisconnect
from fastapi.responses import HTMLResponse, FileResponse
from fastapi.staticfiles import StaticFiles
from fastapi.templating import Jinja2Templates
from dotenv import load_dotenv
import json

# Import our custom modules
from schemas import (
    TextRequest, TTSResponse, STTResponse, VoiceAgentResponse, 
    HealthResponse, ErrorResponse
)
from services import TTSService, STTService, LLMService, ChatManager
from utils import (
    setup_logging, generate_session_id, generate_filename, 
    ensure_upload_directory, validate_audio_file, get_env_variable,
    create_error_response, create_success_response
)

# =============================================================================
# APPLICATION SETUP
# =============================================================================

# Load environment variables
load_dotenv()

# Setup logging
setup_logging(log_level=os.getenv("LOG_LEVEL", "INFO"))
logger = logging.getLogger(__name__)

# Initialize FastAPI app
app = FastAPI(
    title="AI Voice Agent",
    description="Production-ready voice-to-voice conversational AI with comprehensive error handling",
    version="2.0.0",
    docs_url="/docs",
    redoc_url="/redoc"
)

# Setup static files and templates
app.mount("/static", StaticFiles(directory="static"), name="static")
templates = Jinja2Templates(directory="templates")

# Ensure upload directory exists
ensure_upload_directory()

# =============================================================================
# SERVICE INITIALIZATION
# =============================================================================

# Initialize services
tts_service = TTSService()
stt_service = STTService()
llm_service = LLMService()
chat_manager = ChatManager()

logger.info("AI Voice Agent services initialized")

# =============================================================================
# MIDDLEWARE & STARTUP EVENTS
# =============================================================================

@app.on_event("startup")
async def startup_event():
    """Application startup tasks"""
    logger.info("üöÄ Starting AI Voice Agent Server...")
    logger.info("üìä Features: TTS, STT, LLM, Voice-to-Voice Chat, Conversational Memory")
    logger.info("üåê Server will start at: http://localhost:8000")
    logger.info("üí° Open your browser and go to http://localhost:8000 to start using the AI Voice Agent!")
    
    # Check service availability
    services_status = {
        "TTS": "‚úÖ" if tts_service.is_available() else "‚ùå",
        "STT": "‚úÖ" if stt_service.is_available() else "‚ùå", 
        "LLM": "‚úÖ" if llm_service.is_available() else "‚ùå"
    }
    
    logger.info(f"Services status: {services_status}")

@app.on_event("shutdown")
async def shutdown_event():
    """Application shutdown tasks"""
    logger.info("üõë Shutting down AI Voice Agent Server...")

# =============================================================================
# MAIN ROUTES
# =============================================================================

@app.get("/", response_class=HTMLResponse)
async def read_root(request: Request):
    """Serve the main application interface"""
    return templates.TemplateResponse("index.html", {"request": request})

@app.get("/health", response_model=HealthResponse)
async def health_check():
    """Health check endpoint"""
    services = {
        "tts": "available" if tts_service.is_available() else "unavailable",
        "stt": "available" if stt_service.is_available() else "unavailable",
        "llm": "available" if llm_service.is_available() else "unavailable"
    }
    
    all_available = all(status == "available" for status in services.values())
    
    return HealthResponse(
        status="healthy" if all_available else "degraded",
        message="All services operational" if all_available else "Some services unavailable",
        services=services,
        timestamp=datetime.now()
    )

# =============================================================================
# WEBSOCKET ENDPOINTS
# =============================================================================

class ConnectionManager:
    """Manages WebSocket connections"""
    
    def __init__(self):
        self.active_connections: list[WebSocket] = []
    
    async def connect(self, websocket: WebSocket):
        """Accept a new WebSocket connection"""
        await websocket.accept()
        self.active_connections.append(websocket)
        logger.info(f"New WebSocket connection established. Total connections: {len(self.active_connections)}")
    
    def disconnect(self, websocket: WebSocket):
        """Remove a WebSocket connection"""
        if websocket in self.active_connections:
            self.active_connections.remove(websocket)
            logger.info(f"WebSocket connection closed. Total connections: {len(self.active_connections)}")
    
    async def send_personal_message(self, message: str, websocket: WebSocket):
        """Send a message to a specific WebSocket connection"""
        try:
            await websocket.send_text(message)
        except Exception as e:
            logger.error(f"Error sending message to WebSocket: {e}")
            self.disconnect(websocket)
    
    async def broadcast(self, message: str):
        """Send a message to all connected WebSocket clients"""
        disconnected = []
        for connection in self.active_connections:
            try:
                await connection.send_text(message)
            except Exception as e:
                logger.error(f"Error broadcasting to WebSocket: {e}")
                disconnected.append(connection)
        
        # Remove disconnected connections
        for connection in disconnected:
            self.disconnect(connection)

# Initialize connection manager
manager = ConnectionManager()

@app.websocket("/ws")
async def websocket_endpoint(websocket: WebSocket):
    """WebSocket endpoint for real-time communication"""
    await manager.connect(websocket)
    
    try:
        while True:
            # Receive message from client
            data = await websocket.receive_text()
            logger.info(f"Received WebSocket message: {data}")
            
            try:
                # Try to parse as JSON
                message_data = json.loads(data)
                message_type = message_data.get("type", "echo")
                message_content = message_data.get("message", data)
                
                # Handle different message types
                if message_type == "echo":
                    response = {
                        "type": "echo_response",
                        "original": message_content,
                        "echo": f"Server echo: {message_content}",
                        "timestamp": datetime.now().isoformat(),
                        "server": "AI Voice Agent v2.0"
                    }
                elif message_type == "ping":
                    response = {
                        "type": "pong",
                        "message": "pong",
                        "timestamp": datetime.now().isoformat(),
                        "server": "AI Voice Agent v2.0"
                    }
                elif message_type == "status":
                    response = {
                        "type": "status_response",
                        "status": "online",
                        "connections": len(manager.active_connections),
                        "services": {
                            "tts": "available" if tts_service.is_available() else "unavailable",
                            "stt": "available" if stt_service.is_available() else "unavailable",
                            "llm": "available" if llm_service.is_available() else "unavailable"
                        },
                        "timestamp": datetime.now().isoformat(),
                        "server": "AI Voice Agent v2.0"
                    }
                else:
                    # Default echo behavior for unknown types
                    response = {
                        "type": "echo_response",
                        "original": data,
                        "echo": f"Server received: {data}",
                        "timestamp": datetime.now().isoformat(),
                        "server": "AI Voice Agent v2.0"
                    }
                
                # Send JSON response
                await manager.send_personal_message(json.dumps(response), websocket)
                
            except json.JSONDecodeError:
                # Handle plain text messages
                response = {
                    "type": "text_response",
                    "original": data,
                    "echo": f"Server echo: {data}",
                    "timestamp": datetime.now().isoformat(),
                    "server": "AI Voice Agent v2.0"
                }
                await manager.send_personal_message(json.dumps(response), websocket)
                
    except WebSocketDisconnect:
        manager.disconnect(websocket)
        logger.info("WebSocket client disconnected")
    except Exception as e:
        logger.error(f"WebSocket error: {e}")
        manager.disconnect(websocket)

# =============================================================================
# TTS ENDPOINTS
# =============================================================================

@app.post("/tts/generate", response_model=TTSResponse)
async def generate_tts(request: TextRequest):
    """Generate speech from text"""
    try:
        logger.info(f"TTS request for text: {request.text[:50]}...")
        
        if not request.text.strip():
            return TTSResponse(
                status="error",
                error="Empty text provided"
            )
        
        response = await tts_service.generate_speech(request.text, request.voice_id)
        return response
        
    except Exception as e:
        logger.error(f"TTS endpoint error: {str(e)}")
        return TTSResponse(
            status="error",
            error="TTS service failed"
        )

@app.post("/tts/echo", response_model=TTSResponse)
async def echo_tts(request: TextRequest):
    """Echo bot with TTS response"""
    try:
        echo_text = f"You said: {request.text}"
        response = await tts_service.generate_speech(echo_text)
        
        if response.status == "success":
            response.message = f"Echo: {request.text}"
            
        return response
        
    except Exception as e:
        logger.error(f"Echo TTS error: {str(e)}")
        return TTSResponse(
            status="error",
            error="Echo service failed"
        )

# =============================================================================
# STT ENDPOINTS  
# =============================================================================

@app.post("/transcribe/file", response_model=STTResponse)
async def transcribe_audio_file(audio_file: UploadFile = File(...)):
    """Transcribe uploaded audio file"""
    try:
        logger.info(f"STT request for file: {audio_file.filename}")
        
        # Validate file
        if not audio_file.filename:
            return STTResponse(
                status="error",
                error="No file provided"
            )
        
        # Save uploaded file
        filename = generate_filename(extension="webm")
        file_path = Path("uploads") / filename
        
        with open(file_path, "wb") as buffer:
            shutil.copyfileobj(audio_file.file, buffer)
        
        # Validate saved file
        if not validate_audio_file(str(file_path)):
            file_path.unlink(missing_ok=True)
            return STTResponse(
                status="error",
                error="Invalid or empty audio file"
            )
        
        # Transcribe
        response = await stt_service.transcribe_audio(str(file_path))
        
        # Cleanup
        file_path.unlink(missing_ok=True)
        
        return response
        
    except Exception as e:
        logger.error(f"STT endpoint error: {str(e)}")
        return STTResponse(
            status="error",
            error="Transcription service failed"
        )

# =============================================================================
# LLM ENDPOINTS
# =============================================================================

@app.post("/llm/query", response_model=VoiceAgentResponse)
async def llm_query_with_voice(audio_file: UploadFile = File(...)):
    """Process voice input through full AI pipeline"""
    session_id = generate_session_id()
    
    try:
        logger.info(f"LLM voice query for session: {session_id}")
        
        # Step 1: Save and validate audio
        filename = generate_filename()
        file_path = Path("uploads") / filename
        
        with open(file_path, "wb") as buffer:
            shutil.copyfileobj(audio_file.file, buffer)
        
        if not validate_audio_file(str(file_path)):
            file_path.unlink(missing_ok=True)
            return VoiceAgentResponse(
                status="error",
                error_type="empty_audio",
                fallback_message="No audio detected. Please record a clear message."
            )
        
        # Step 2: Transcribe audio
        stt_response = await stt_service.transcribe_audio(str(file_path))
        file_path.unlink(missing_ok=True)
        
        if stt_response.status != "success":
            fallback_audio = await tts_service.generate_fallback_speech(
                "Speech recognition failed. Please speak clearly and try again."
            )
            return VoiceAgentResponse(
                status="error",
                error_type="transcription_failed", 
                fallback_message="Speech recognition failed. Please speak clearly and try again.",
                audio_url=fallback_audio
            )
        
        user_message = stt_response.transcript
        
        # Step 3: Generate AI response
        llm_response = await llm_service.generate_response(user_message)
        
        if llm_response.status != "success":
            fallback_audio = await tts_service.generate_fallback_speech(
                "My AI brain is having trouble right now. Please try again in a moment."
            )
            return VoiceAgentResponse(
                status="error",
                error_type="llm_error",
                user_message=user_message,
                fallback_message="My AI brain is having trouble right now. Please try again in a moment.",
                audio_url=fallback_audio
            )
        
        ai_response = llm_response.response
        
        # Step 4: Generate voice response
        tts_response = await tts_service.generate_speech(ai_response)
        
        if tts_response.status == "success":
            return VoiceAgentResponse(
                status="success",
                user_message=user_message,
                assistant_message=ai_response,
                audio_url=tts_response.audio_url,
                session_id=session_id,
                timestamp=datetime.now()
            )
        else:
            return VoiceAgentResponse(
                status="partial_success",
                user_message=user_message,
                assistant_message=ai_response,
                fallback_message="AI responded but voice synthesis failed",
                session_id=session_id,
                timestamp=datetime.now()
            )
            
    except Exception as e:
        logger.error(f"LLM pipeline error: {str(e)}")
        fallback_audio = await tts_service.generate_fallback_speech(
            "Something went wrong with my processing. Please try again."
        )
        return VoiceAgentResponse(
            status="error",
            error_type="pipeline_error",
            fallback_message="Something went wrong with my processing. Please try again.",
            audio_url=fallback_audio,
            session_id=session_id
        )

# =============================================================================
# CONVERSATIONAL AGENT ENDPOINTS
# =============================================================================

@app.post("/agent/chat/{session_id}", response_model=VoiceAgentResponse)
async def conversational_voice_agent(session_id: str, audio_file: UploadFile = File(...)):
    """Complete conversational voice agent with memory"""
    try:
        logger.info(f"Conversational agent request for session: {session_id}")
        
        # Check service availability
        if not all([tts_service.is_available(), stt_service.is_available(), llm_service.is_available()]):
            missing_services = []
            if not tts_service.is_available(): missing_services.append("TTS")
            if not stt_service.is_available(): missing_services.append("STT") 
            if not llm_service.is_available(): missing_services.append("LLM")
            
            error_msg = f"Required services unavailable: {', '.join(missing_services)}. Please check your API keys."
            fallback_audio = await tts_service.generate_fallback_speech(error_msg)
            
            return VoiceAgentResponse(
                status="error",
                error_type="api_keys_missing",
                fallback_message=error_msg,
                audio_url=fallback_audio,
                session_id=session_id
            )
        
        # Step 1: Process audio file
        filename = generate_filename()
        file_path = Path("uploads") / filename
        
        with open(file_path, "wb") as buffer:
            shutil.copyfileobj(audio_file.file, buffer)
        
        if not validate_audio_file(str(file_path)):
            file_path.unlink(missing_ok=True)
            error_msg = "No audio detected. Please record a clear message and try again."
            fallback_audio = await tts_service.generate_fallback_speech(error_msg)
            
            return VoiceAgentResponse(
                status="error",
                error_type="empty_audio",
                fallback_message=error_msg,
                audio_url=fallback_audio,
                session_id=session_id
            )
        
        # Step 2: Speech-to-Text
        stt_response = await stt_service.transcribe_audio(str(file_path))
        file_path.unlink(missing_ok=True)
        
        if stt_response.status != "success":
            error_msg = "I couldn't understand what you said. Please speak clearly and try again."
            fallback_audio = await tts_service.generate_fallback_speech(error_msg)
            
            return VoiceAgentResponse(
                status="error",
                error_type="no_speech_detected" if "No speech" in str(stt_response.error) else "transcription_failed",
                fallback_message=error_msg,
                audio_url=fallback_audio,
                session_id=session_id
            )
        
        user_message = stt_response.transcript
        
        # Step 3: Get conversation history and generate LLM response
        chat_history = chat_manager.get_recent_context(session_id, max_messages=10)
        llm_response = await llm_service.generate_conversational_response(user_message, chat_history)
        
        if llm_response.status != "success":
            error_msg = "My AI brain is having trouble right now. Please try again in a moment."
            fallback_audio = await tts_service.generate_fallback_speech(error_msg)
            
            return VoiceAgentResponse(
                status="error",
                error_type="llm_error",
                user_message=user_message,
                fallback_message=error_msg,
                audio_url=fallback_audio,
                session_id=session_id
            )
        
        ai_response = llm_response.response
        
        # Step 4: Save to chat history
        chat_manager.add_message(session_id, "user", user_message)
        chat_manager.add_message(session_id, "assistant", ai_response)
        
        # Step 5: Generate speech response
        tts_response = await tts_service.generate_speech(ai_response)
        
        if tts_response.status == "success":
            logger.info(f"Complete conversation successful for session: {session_id}")
            return VoiceAgentResponse(
                status="success",
                user_message=user_message,
                assistant_message=ai_response,
                audio_url=tts_response.audio_url,
                session_id=session_id,
                timestamp=datetime.now()
            )
        else:
            logger.warning(f"TTS failed but conversation succeeded for session: {session_id}")
            return VoiceAgentResponse(
                status="partial_success", 
                user_message=user_message,
                assistant_message=ai_response,
                fallback_message="I can respond but my voice synthesis isn't working right now.",
                session_id=session_id,
                timestamp=datetime.now()
            )
            
    except Exception as e:
        logger.error(f"Conversational agent error: {str(e)}")
        error_msg = "Something unexpected happened. Please try again."
        fallback_audio = await tts_service.generate_fallback_speech(error_msg)
        
        return VoiceAgentResponse(
            status="error",
            error_type="unexpected_error",
            fallback_message=error_msg,
            audio_url=fallback_audio,
            session_id=session_id
        )

@app.get("/agent/history/{session_id}")
async def get_chat_history(session_id: str):
    """Get chat history for a session"""
    try:
        history = chat_manager.get_history_as_dict(session_id)
        return create_success_response(
            {"session_id": session_id, "messages": history, "count": len(history)},
            "Chat history retrieved successfully"
        )
    except Exception as e:
        logger.error(f"Error retrieving chat history: {str(e)}")
        return create_error_response("history_error", "Failed to retrieve chat history")

# =============================================================================
# FILE MANAGEMENT ENDPOINTS
# =============================================================================

@app.post("/upload")
async def upload_file(file: UploadFile = File(...)):
    """Upload and save audio file"""
    try:
        if not file.filename:
            raise HTTPException(status_code=400, detail="No file provided")
        
        filename = generate_filename()
        file_path = Path("uploads") / filename
        
        with open(file_path, "wb") as buffer:
            shutil.copyfileobj(file.file, buffer)
        
        logger.info(f"File uploaded successfully: {filename}")
        return create_success_response(
            {"filename": filename, "path": str(file_path)},
            "File uploaded successfully"
        )
        
    except Exception as e:
        logger.error(f"File upload error: {str(e)}")
        raise HTTPException(status_code=500, detail="File upload failed")

@app.get("/files/{filename}")
async def get_file(filename: str):
    """Download file by filename"""
    try:
        file_path = Path("uploads") / filename
        
        if not file_path.exists():
            raise HTTPException(status_code=404, detail="File not found")
        
        return FileResponse(
            path=str(file_path),
            media_type="audio/wav",
            filename=filename
        )
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"File retrieval error: {str(e)}")
        raise HTTPException(status_code=500, detail="File retrieval failed")

@app.get("/files")
async def file_manager(request: Request):
    """File management interface"""
    return templates.TemplateResponse("file_manager.html", {"request": request})

# =============================================================================
# LEGACY COMPATIBILITY ENDPOINTS
# =============================================================================

@app.get("/api/hello")
async def hello():
    """Legacy compatibility endpoint"""
    return {"message": "AI Voice Agent API is running", "status": "success", "version": "2.0.0"}

@app.get("/favicon.ico")
async def favicon():
    """Favicon endpoint"""
    return {"message": "No favicon configured"}

# =============================================================================
# APPLICATION ENTRY POINT
# =============================================================================

if __name__ == "__main__":
    import uvicorn
    
    host = get_env_variable("HOST", "0.0.0.0")
    port = int(get_env_variable("PORT", "8000"))
    debug = get_env_variable("DEBUG", "True").lower() == "true"
    
    uvicorn.run(
        "app:app",
        host=host,
        port=port,
        reload=debug,
        log_level="info"
    )
